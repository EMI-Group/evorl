rollout_length: 32
continuous_action: true
env: ant
num_envs: 8 # train_batch_size = rollout_length * num_envs = 256
optimizer:
  lr: 0.0001
  loss_weights:
    actor_loss: 1.0
    critic_loss: 0.5
    actor_entropy_loss: -0.01

gae_lambda: 0.95
discount: 0.99

actor_hidden_layer_sizes: [32, 32]
critic_hidden_layer_sizes: [32, 32]