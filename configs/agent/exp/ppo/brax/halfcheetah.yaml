# @package _global_

defaults:
  - /agent/ppo
  - _self_

normalize_obs: true
num_envs: 2048
minibatch_size: 10240 # num_minibatches = batch_size / num_minibatches = 32
rollout_length: 160
reuse_rollout_epochs: 8
discount: 0.95

total_timesteps: 50000000

num_eval_envs: 128
eval_episodes: 128 # should be divided by num_eval_envs
eval_interval: 5
