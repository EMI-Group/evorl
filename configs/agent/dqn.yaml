# @package _global_

workflow_cls: evorl.agents.dqn.DQNWorkflow

num_envs: 1

rollout_length: 1
discount: 0.99
exploration_epsilon: 0.1
total_timesteps: 50000
target_network_update_interval: 20
learning_starts: 0

num_eval_envs: 1
eval_interval: 20
eval_episodes: 20 # should be divided by num_eval_envs

train_batch_size: 256
optimizer:
  lr: 0.0003
  loss_weights:
    q_loss: 1.0

replay_buffer:
  capacity: 1000000
  min_size: 10000

agent_network:
  continuous_action: false
  q_hidden_layer_sizes: [32, 32]